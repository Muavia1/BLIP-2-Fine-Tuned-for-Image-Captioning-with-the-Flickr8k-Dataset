import gradio as gr
from transformers import Blip2ForConditionalGeneration, AutoProcessor, BitsAndBytesConfig, AutoModel
from peft import PeftModel, PeftConfig
from PIL import Image
import torch

model = Blip2ForConditionalGeneration.from_pretrained("muaviaabdulmoiz/blip2-image-captions-generator")

processor = AutoProcessor.from_pretrained("Salesforce/blip2-opt-2.7b")

device = "cuda" if torch.cuda.is_available() else "cpu"
model.to(device)

# Caption generation function
def generate_caption(image):
    image = image.convert("RGB")
    inputs = processor(images=image, return_tensors="pt").to(device, torch.float16)
    pixel_values = inputs.pixel_values

    with torch.no_grad():
        generated_ids = model.generate(pixel_values=pixel_values, max_length=25)

    caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
    return caption

# Gradio Interface
iface = gr.Interface(
    fn=generate_caption,
    inputs=gr.Image(type="pil"),
    outputs="text",
    title="BLIP2 Image Caption Generator",
    description="Upload an image and get a caption generated by a fine-tuned BLIP2 model."
)

iface.launch()
